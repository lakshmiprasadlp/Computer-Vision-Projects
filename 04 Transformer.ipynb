{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17a5f78a",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### ğŸ” **1. Vision Transformer (ViT)**\n",
    "\n",
    "**Use Case:** Primarily for **image classification**\n",
    "\n",
    "| Aspect          | Details                                                                            |\n",
    "| --------------- | ---------------------------------------------------------------------------------- |\n",
    "| ğŸ”§ Architecture | Pure transformer (no convolutions); splits images into patches                     |\n",
    "| ğŸ§  Pretraining  | Requires large datasets (e.g., JFT-300M) for best performance                      |\n",
    "| ğŸ§ª Tasks        | Image classification (main), also adapted for segmentation (e.g., Segmenter, SETR) |\n",
    "| âš¡ Pros          | Simple, elegant, scalable                                                          |\n",
    "| âŒ Cons          | Poor performance on small datasets without data augmentation or distillation       |\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ¯ **2. DETR (DEtection TRansformer)**\n",
    "\n",
    "**Use Case:** **Object detection and instance segmentation**\n",
    "\n",
    "| Aspect          | Details                                                                      |\n",
    "| --------------- | ---------------------------------------------------------------------------- |\n",
    "| ğŸ”§ Architecture | CNN backbone (e.g., ResNet) + Transformer encoder-decoder                    |\n",
    "| ğŸ§  Core Idea    | Treats object detection as a direct set prediction task (no anchors, no NMS) |\n",
    "| ğŸ§ª Tasks        | Object detection, instance segmentation (via mask head)                      |\n",
    "| âš¡ Pros          | Clean, end-to-end training                                                   |\n",
    "| âŒ Cons          | Slow convergence, harder to train (solved by Deformable DETR)                |\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸŒ€ **3. Swin Transformer (Shifted Windows)**\n",
    "\n",
    "**Use Case:** **All vision tasks** (classification, detection, segmentation)\n",
    "\n",
    "| Aspect          | Details                                                                                        |\n",
    "| --------------- | ---------------------------------------------------------------------------------------------- |\n",
    "| ğŸ”§ Architecture | Hierarchical transformer with shifted window attention                                         |\n",
    "| ğŸ§  Core Idea    | Local attention with window shifting to allow cross-window interaction                         |\n",
    "| ğŸ§ª Tasks        | Classification, detection, semantic segmentation, instance segmentation, panoptic segmentation |\n",
    "| âš¡ Pros          | Highly efficient, scalable, CNN-like feature maps                                              |\n",
    "| âŒ Cons          | Slightly more complex to implement than ViT                                                    |\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… **Summary Table**\n",
    "\n",
    "| Model    | Classification | Object Detection | Semantic Segmentation              | Instance Segmentation  | Panoptic Segmentation |\n",
    "| -------- | -------------- | ---------------- | ---------------------------------- | ---------------------- | --------------------- |\n",
    "| **ViT**  | âœ… Yes          | âš ï¸ Limited       | âš ï¸ Limited (e.g., SETR, Segmenter) | âŒ No                   | âŒ No                  |\n",
    "| **DETR** | âŒ No           | âœ… Yes            | âŒ No                               | âœ… Yes (with mask head) | âŒ Limited             |\n",
    "| **Swin** | âœ… Yes          | âœ… Yes            | âœ… Yes                              | âœ… Yes                  | âœ… Yes                 |\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149d1b66",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
